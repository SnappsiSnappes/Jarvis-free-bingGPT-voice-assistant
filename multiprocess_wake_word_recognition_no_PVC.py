


def main123(conn=None,target=str):
    import speech_recognition as sr
    import asyncio
    recognizer = sr.Recognizer()
    microphone = sr.Microphone()
    
    with microphone as source:
        recognizer.adjust_for_ambient_noise(source)
    
    print('Listening for cancel keyword...')
    while True:
        with microphone as source:
            audio = recognizer.listen(source)
        try:
            text = recognizer.recognize_google(audio, language='ru-RU')
            print(f"Recognized text: {text}")
            if target in text.lower():
                print('–æ—Ç–º–µ–Ω–∞')
                print("Cancel keyword detected. Cancelling all tasks.")
                canceled = True
                conn.send(canceled)
                return
        except sr.UnknownValueError:
            pass
        except sr.RequestError as e:
            print(f"Request error: {e}")

# if __name__ == "__main__":
#     target = '–æ—Ç–º–µ–Ω–∞'
#     import asyncio
#     from rich import print
#     import speech_recognition as sr
#     asyncio.run(listen_for_cancel(target))



def main1234(conn=None):
    import pvporcupine
    import configparser

    from pvrecorder import PvRecorder
    from rich import print
    config = configparser.ConfigParser()
    config.read('config.ini')
    keyward_path = r'vosk_+_pvporcupine\–æ—Ç–º–µ–Ω–∞_ru_windows_v2_2_0.ppn'
    model_path = r'vosk_+_pvporcupine\porcupine_params_ru.pv'
    PICOVOICE_TOKEN   = config.get('PICOVOICE_TOKEN','token')
    porcupine         = pvporcupine.create(
        access_key    = PICOVOICE_TOKEN,
        keyword_paths=[f'{keyward_path}'], 
        keywords=['–æ—Ç–º–µ–Ω–∞'],
        model_path=f'{model_path}',
        sensitivities = [0]
    )


    # VOSK
    MICROPHONE_INDEX  = int(config.get('MIC','microphone_index'))
    # model            = vosk.Model("model_small")
    # samplerate       = 16000
    # BUFFER_SIZE      = 512                        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–π—Ç –≤ –±—É—Ñ–µ—Ä–µ –∑–∞–ø–∏—Å–∏
    # SAMPLE_RATE      = 16000                      # –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
    # device           = MICROPHONE_INDEX
    # kaldi_rec         = vosk.KaldiRecognizer(model, samplerate)
    # p = pyaudio.PyAudio()
    recorder = PvRecorder(device_index=MICROPHONE_INDEX, frame_length=porcupine.frame_length)


    # rec   = vosk.KaldiRecognizer(model, SAMPLE_RATE)
    # stream = p.open(format=pyaudio.paInt16, channels=1, rate=SAMPLE_RATE, input=True,
    #                 frames_per_buffer=BUFFER_SIZE, input_device_index=MICROPHONE_INDEX)

    # def get_next_audio_frame():
    #   pass
    # while True:
    #   audio_frame = get_next_audio_frame()
    #   keyword_index = porcupine.process(audio_frame)
    """
    if keyword_index == 0:
    # detected `–æ—Ç–º–µ–Ω–∞`
    elif keyword_index == 1:
    # detected `–ª—é–±–æ–µ –¥—Ä—É–≥–æ–µ —Å–ª–æ–≤–æ...üëå`
    """
    recorder.start()
    while True:
        # –°—á–∏—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–æ—Ç–æ–∫–∞
        pcm = recorder.read()
        keyword_index = porcupine.process(pcm)
        if keyword_index == 0:
            print('–æ—Ç–º–µ–Ω–∞')
            #conn.send('–æ—Ç–º–µ–Ω–∞')
            
if __name__ == '__main__':
    main123(None,'–æ—Ç–º–µ–Ω–∞')
    # main(conn)